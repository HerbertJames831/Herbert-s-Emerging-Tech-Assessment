{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac61a4ad-6fbc-40f4-96ff-ad08a1eabd36",
   "metadata": {},
   "source": [
    "# Task 1 - Third-Order Letter Approximation Model\n",
    "\n",
    "## Introduction\n",
    "\n",
    "A trigram model will be created based on five English books in this notebook(trigrams.ipynb). The five English books that will be used for this task are:\n",
    "\n",
    "1. The Great Gatsby by F. Scott Fitzgerald\n",
    "2. The Odyssey by Homer\n",
    "3. Sense and Sensibility by Jane Austen\n",
    "4. The Tempest by William Shakespeare\n",
    "5. The Sign of the Four by Arthur Conan Doyle\n",
    "\n",
    "The steps that are involved during this process are: \n",
    "\n",
    "1. All characters except ASCII letters(both uppercase and lowercase), spaces and full stops will be removed\n",
    "\n",
    "2. All letters will be changed to uppercase\n",
    "\n",
    "3. A trigram model will be created which will count the amount of times each sequence of three characters(each trigram) emerges\n",
    "\n",
    "\n",
    "The final outcome is a dictionary that links each book with its corresponding trigram frequency model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b434b820-85f6-47d0-a891-6ce8e897e376",
   "metadata": {},
   "source": [
    "## Setting Up Imports and Constants\n",
    "\n",
    "1. The os module is beneficial because methods that interact with the operating system are provided for example managing directories and files\n",
    "\n",
    "2. The defaultdict is known as a container in Python and in the collections module, the defaultdict is defined. The defaultdict is useful for assigning a default value automatically to a key that is non-existent in the dictionary. This is advantageous for counting the amount of times each trigram appears; without manually having to verify if keys are present.\n",
    "\n",
    "3. The BOOKS_DIRECTORY Constant is utilized to indicate the folder that is storing the books \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f3df4a-106c-43a5-b396-8728f0f70f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from itertools import islice\n",
    "\n",
    "BOOKS_DIRECTORY = \"books/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b50b07-677e-4e4d-ab51-cc68bbb1a65f",
   "metadata": {},
   "source": [
    "## Cleaning Text \n",
    "\n",
    "1. The text is preprocessed as a way of removing unnecessary characters by the  clean_book_text function.\n",
    "   \n",
    "2. This makes sure that only full stops, spaces and letters remain in the text.\n",
    "   \n",
    "3. All letters in the cleaned text are changed to uppercase to maintain consistency.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e36ebb9-6ebc-40aa-8eeb-378f511d91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_book_text(book_title):\n",
    "    book_file_path = os.path.join(BOOKS_DIRECTORY, book_title)\n",
    "    try:\n",
    "        with open(book_file_path, 'r', encoding='utf-8') as file:\n",
    "            book_text = file.read()\n",
    "\n",
    "            book_text = ''.join(character if character.isalpha() or character == ' ' or character == '.' else '' for character in book_text)\n",
    "            return book_text.upper()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Sorry the file {book_title} was not found in the directory!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ec1f1-cde0-40eb-ab13-52beed790a1a",
   "metadata": {},
   "source": [
    "## Creating Trigrams\n",
    "Sequences of three consecutive characters which are also known as trigrams from the preprocessed text is extracted by the create_trigrams function. A dictionary is utilized to track the frequency of each trigram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f08058c-9bf6-46dc-82a0-b9ca89887d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trigrams(book_text):\n",
    "    trigram_frequencies = defaultdict(int)\n",
    "    for i in range(len(book_text) - 2):\n",
    "        trigram = book_text[i:i+3]\n",
    "        trigram_frequencies[trigram] += 1\n",
    "    return trigram_frequencies\n",
    "        \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791fd2a5-16ec-49be-bf61-7846211fbe92",
   "metadata": {},
   "source": [
    "## Preprocessing Books For Trigram Model\n",
    "\n",
    "All the book files are processed in this section. The steps that are involved in this process are:\n",
    "\n",
    "1. The file contents are read\n",
    "\n",
    "2. The clean_book_text function is utilized to clean the text\n",
    "\n",
    "3. The create_trigrams function is utilized to create a trigram model\n",
    "\n",
    "4. For each book, the results are stored in a dictionary\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db38107a-456f-463d-a08c-42e20ead38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_file_names = [\n",
    "\"the_great_gatsby.txt\",\n",
    "\"the_odyssey.txt\",\n",
    "\"sense_and_sensibility.txt\",\n",
    "\"the_tempest.txt\",\n",
    "\"the_sign_of_the_four.txt\"\n",
    "]\n",
    "\n",
    "book_trigram_models = {}\n",
    "\n",
    "for book_file in book_file_names:\n",
    "    cleaned_book_text = clean_book_text(book_file)\n",
    "    if cleaned_book_text:\n",
    "        trigram_model = create_trigrams(cleaned_book_text)\n",
    "        book_trigram_models[book_file] = trigram_model\n",
    "        print(f\"Displaying the first 30 trigrams extracted from '{book_file}':\")\n",
    "        for trigram, frequency in islice(trigram_model.items(), 30):\n",
    "            print(f\"Trigram: {trigram}, Frequency: {frequency}\")\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67a438e-1927-4174-9ccc-5e03adaa7784",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook successfully preprocessed books and for each book, trigram models were created. The trigram models that were created are stored in the book_trigram_models variable; which can be utilized for further analysis or visualization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902ae6db-73c5-468a-bbd6-4599ed4683f8",
   "metadata": {},
   "source": [
    "# Task 2 - Third-Order Letter Approximation Generation\n",
    "\n",
    "## Introduction \n",
    "\n",
    "The trigram models that were created in Task 1; are going to be utilized to generate a string of 10,000 characters for this task.\n",
    "\n",
    "This process starts with the string \"TH\" and the text is built by adding characters one at a time. The trigram frequencies which are extracted from the text of the books are utilized to probabilistically select the next character.\n",
    "\n",
    "The steps that are involved during this process are:\n",
    "\n",
    "1. The trigram model for each book from Task 1 must be utilized.\n",
    "\n",
    "2. Next begin with the string \"TH\"\n",
    "\n",
    "3. The trigram frequencies that begin with the previous characters of the generated text to determine probabilistically the next character must be utilized.\n",
    "\n",
    "4. The selected character must be added to the generated text and subsequently the process must be repeated until the specified length(10,000 characters) is reached.\n",
    "\n",
    "5. For each book, the generated text must be saved to an individual file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb3d4d0-8b87-4fdc-a87f-a9085757f0f5",
   "metadata": {},
   "source": [
    "## Creating Text Utilizing Trigram Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ff0967-abbc-4eb0-8cc9-ac86c9e9523b",
   "metadata": {},
   "source": [
    "The text is created by applying the trigram models that were created in Task 1. This is done by utilizing the create_book_text_from_trigram_model function.\n",
    "\n",
    "This is the logic for the function create_book_text_from_trigram_model function:\n",
    "\n",
    "1. Commence with a string of two characters for example \"TH\"\n",
    "\n",
    "2. In the trigram model, determine all trigrams that begin with the previous two characters of the current text. This must be carried out for each new character.\n",
    "\n",
    "The next character is determined probabilistically by utilizing the trigram frequencies\n",
    "\n",
    "3. However the process ends if no matching trigrams are located or when the specified length is reached.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3a37a3-a8c2-451c-a84b-f6fea18cac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def create_book_text_from_trigram_model(trigram_model, starting_string, length):\n",
    "    if len(starting_string) != 2:\n",
    "        raise ValueError(\"The starting string must be 2 characters long.\")\n",
    "\n",
    "    created_book_text = starting_string.upper()\n",
    "    while len(created_book_text) < length:\n",
    "        previous_two_characters = created_book_text[-2:]\n",
    "\n",
    "        matching_trigrams = {trigram: frequency for trigram, frequency in trigram_model.items() if trigram.startswith(previous_two_characters)}\n",
    "\n",
    "        print(f\"There are the previous two characters: {previous_two_characters}\")\n",
    "        print(f\"There are the matching trigrams: {matching_trigrams}\")\n",
    "        \n",
    "                             \n",
    "        if not matching_trigrams:\n",
    "           print(f\"Warning: There are no trigrams found beginning with '{previous_two_characters}'. Restarting from 'TH'!\")\n",
    "           created_book_text = \"TH\"\n",
    "           continue\n",
    "\n",
    "        third_characters = [trigram[2] for trigram in matching_trigrams.keys()]\n",
    "        trigram_frequencies = list(matching_trigrams.values())\n",
    "\n",
    "        next_character = random.choices(third_characters, weights=trigram_frequencies, k=1)[0]\n",
    "\n",
    "        created_book_text += next_character\n",
    "\n",
    "    return created_book_text\n",
    "\n",
    "    \n",
    "\n",
    "  \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb81199c-33c2-4dd5-9b1a-af6c8104e819",
   "metadata": {},
   "source": [
    "## Creating Text for Each Book\n",
    "\n",
    "A 10,000 character text for each book is created by utilizing the create_book_text_from_trigram_model.\n",
    "\n",
    "The steps that are involved in this process are: \n",
    "\n",
    "1. Begin with the string \"TH\"\n",
    "\n",
    "2. The trigram models for the books are utilized to create the text.\n",
    "\n",
    "3. The created text for each book is saved to an individual file for example (the_sign_of_the_four.txt_created_text.txt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02027a6-b771-4ac5-8467-62e4caff0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "created_book_texts = {}\n",
    "\n",
    "created_book_text_length = 10000\n",
    "\n",
    "for book_file, trigram_model in book_trigram_models.items():\n",
    "    print(f\"Creating text for '{book_file}'\")\n",
    "    starting_string = \"TH\"\n",
    "    created_book_text = create_book_text_from_trigram_model(trigram_model, starting_string, created_book_text_length)\n",
    "    created_book_texts[book_file] = created_book_text\n",
    "\n",
    "    output_book_file = f\"{book_file}_created_text.txt\"\n",
    "    with open(output_book_file, \"w\", encoding=\"utf-8\") as file:\n",
    "         file.write(created_book_text)\n",
    "    print(f\"The Created Text is saved to '{output_book_file}'\")\n",
    "    \n",
    "\n",
    "         \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02ad9ed-01f6-4b3f-8786-5693c7e74d41",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "10,000 character texts were successfully created for each book utilizing the trigram models from Task 1. In addition the created texts for each book were successfully stored in individual files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9579dd87-9ec4-4ccc-9b6f-8bba9aeb1600",
   "metadata": {},
   "source": [
    "# Task 3: Analyze Your Model \n",
    "\n",
    "## Introduction\n",
    "\n",
    "The text that was created in Task 2 utilizing the trigram models will be analyzed. The objective is for the percentage of authentic English words in the 10,000 character texts that were created for each book to be calculated.\n",
    "\n",
    "The steps that are involved during this process are:\n",
    "\n",
    "1. A list of authentic English words must be loaded\n",
    "\n",
    "2. Words from the created text must be obtained\n",
    "\n",
    "3. To calculate the percentage of authentic English words, these words must be compared with the dictionary.\n",
    "\n",
    "4. The results for each book must be saved to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119bb254-de4f-45ee-9d07-5c61c140e021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
